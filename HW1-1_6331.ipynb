{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"IRBubL3il3TB"},"source":["### Natcha Jangphiphatnawakit 63340500031"]},{"cell_type":"markdown","metadata":{"id":"7EdbVSmE87En"},"source":["# HW1: Dictionary-based Tokenization \n"]},{"cell_type":"markdown","metadata":{"id":"pJJLm1Ub87Et"},"source":["In this exercise, you are to implement a dictionary-based word segmentation algorithm. There are two Python functions that you need to complete: \n","<br>\n","* maximal_matching\n","* backtrack\n","</br>\n","\n","Also, you have to find how to use word_tokenize() in PythaiNLP along with customer_dict by yourselves."]},{"cell_type":"markdown","metadata":{"id":"DF5Pme7CK3YF"},"source":["## Part1) Your Maximal Matching with Your Dictionary"]},{"cell_type":"markdown","metadata":{"id":"xzs0R06q87Et"},"source":["### Create a toy dictionary to test the algorithm\n","\n","This is based on the example shown in the lecture. \n","You will tokenize the following text string: \"ไปหามเหสี!\"\n","The toy dictoionary provided in this exercise includes all the charaters, syllables, and words that appear that the text string."]},{"cell_type":"code","execution_count":18,"metadata":{"id":"pq3W4p3z87Ev"},"outputs":[],"source":["thai_vocab = [\"ไ\",\"ป\",\"ห\",\"า\",\"ม\",\"เ\",\"ห\",\"ส\",\"ี\",\"ไป\",\"หา\",\"หาม\",\"เห\",\"สี\",\"มเหสี\",\"!\"]"]},{"cell_type":"markdown","metadata":{"id":"ZornooGF87Ew"},"source":["### Maximal matching \n","Complete the maximal matching  function below to tokenize the input text\n"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"Ao4d2E3387Ew"},"outputs":[],"source":["# c is the character array\n","from math import inf #infinity\n","def maximal_matching(c):\n","    #Initialize an empty 2D list\n","    d  =[[None]*len(c) for _ in range(len(c))]\n","    \n","    ####FILL CODE HERE####\n","    \n","    add = 0                                         #for adding value when start new line\n","\n","    for i in range(len(c)):                         #loop line\n","\n","        flag = 0                                    #flag check it has found word in dict first times in each line\n","        ch = \"\"                                     #charater for concating\n","\n","        for j in range(len(c)-i):                   #loop character\n","\n","            ch += c[j+i]                            #concat character for checking\n","           \n","            if ch in thai_vocab:                    #if find word in dict\n","                if (flag == 0):\n","                    flag = 1; \n","                d[i][j+i] = add + flag              #add number of found word\n","             \n","            else:\n","                d[i][j+i] = inf                     #if not found word, append inf\n","       \n","        ls = [list(e) for e in zip(*d)]             #2D list of d transpose\n","        add = min(value for value in ls[i] if value is not None) #number of mininimum words before start new line \n","    \n","    ######################\n","    \n","    return d"]},{"cell_type":"markdown","metadata":{"id":"w7vBXfjM87Ew"},"source":["### Backtracking\n","Complete the backtracking function below to find the tokenzied words.\n","It should return a list containing a pair of the beginning position and the ending position of each word.\n","In this example, it should return: \n","<br>\n","[(0, 1),(2, 3),(4, 8),(9, 9)]\n","<br> \n","#### Each pair contains the position of each word as follows:\n","(0, 1) ไป\n","<br>\n","(2, 3) หา\n","<br>\n","(4, 8) มเหสี\n","<br>\n","(9, 9) !\n"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"SxNFf1IE87Ex"},"outputs":[],"source":["def backtrack(d):\n","    eow = len(d)-1 # End of Word position\n","    word_pos = [] # Word position\n","    ####FILL CODE HERE####\n","\n","    d_T = [list(e) for e in zip(*d)]            #list of d transpose\n","    idx_x = eow                                 #index x (each character)\n","\n","    while(idx_x > 0):                           \n","        pos = []                                #list collect index of each tokenized word\n","        v = min(value for value in d_T[idx_x]  if value is not None) #find min value in d transpose (in column)\n","        idx_y = d_T[idx_x].index(v)             #find index of that value (get row)\n","        pos.append(idx_x)                       \n","        \n","        while(d[idx_y][idx_x] != None):         #loop check element is not None\n","            idx_x -=1                           \n","            if idx_x == 0:                      \n","                idx_x = -1\n","                break\n","            \n","        pos.append(idx_x+1)\n","        pos.reverse()\n","        word_pos.append(tuple(pos))\n","\n","    ######################\n","    word_pos.reverse()\n","    return word_pos\n"]},{"cell_type":"markdown","metadata":{"id":"q0MJkKsh87Ex"},"source":["### Test your maximal matching algorithm on a toy dictionary\n","\n","Expected output:\n","\n","[1, 1, inf, inf, inf, inf, inf, inf, inf, inf] ไ\n","<br>\n","[None, 2, inf, inf, inf, inf, inf, inf, inf, inf] ป\n","<br>\n","[None, None, 2, 2, 2, inf, inf, inf, inf, inf] ห\n","<br>\n","[None, None, None, 3, inf, inf, inf, inf, inf, inf] า\n","<br>\n","[None, None, None, None, 3, inf, inf, inf, 3, inf] ม\n","<br>\n","[None, None, None, None, None, 3, 3, inf, inf, inf] เ\n","<br>\n","[None, None, None, None, None, None, 4, inf, inf, inf] ห\n","<br>\n","[None, None, None, None, None, None, None, 4, 4, inf] ส\n","<br>\n","[None, None, None, None, None, None, None, None, 5, inf] ี\n","<br>\n","[None, None, None, None, None, None, None, None, None, 4] !\n","<br>"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"tsmVQIKS87Ey"},"outputs":[{"name":"stdout","output_type":"stream","text":["[1, 1, inf, inf, inf, inf, inf, inf, inf, inf] ไ\n","[None, 2, inf, inf, inf, inf, inf, inf, inf, inf] ป\n","[None, None, 2, 2, 2, inf, inf, inf, inf, inf] ห\n","[None, None, None, 3, inf, inf, inf, inf, inf, inf] า\n","[None, None, None, None, 3, inf, inf, inf, 3, inf] ม\n","[None, None, None, None, None, 3, 3, inf, inf, inf] เ\n","[None, None, None, None, None, None, 4, inf, inf, inf] ห\n","[None, None, None, None, None, None, None, 4, 4, inf] ส\n","[None, None, None, None, None, None, None, None, 5, inf] ี\n","[None, None, None, None, None, None, None, None, None, 4] !\n"]}],"source":["input_text = \"ไปหามเหสี!\"\n","out = maximal_matching(input_text)\n","for i in range(len(out)):\n","    print(out[i],input_text[i])"]},{"cell_type":"markdown","metadata":{"id":"IVhCMM4d87Ey"},"source":["### Test your backtracking algorithm on a toy dictionary\n","Expected output:\n","<br>\n","ไป|หา|มเหสี|!"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"6Hurbm1f87Ey"},"outputs":[{"name":"stdout","output_type":"stream","text":["ไป|หา|มเหสี|!\n"]}],"source":["def print_tokenized_text(d, input_text):\n","    tokenized_text=[]\n","    for pos in backtrack(d):\n","        # print(pos)\n","        tokenized_text.append(input_text[pos[0]:pos[1]+1])\n","\n","    print(\"|\".join(tokenized_text))\n","    \n","print_tokenized_text(out,input_text)"]},{"cell_type":"markdown","metadata":{"id":"57rP9cTU87Ez"},"source":["## Part2) Your Maximal Matching with Real Dictionary"]},{"cell_type":"markdown","metadata":{"id":"V306h7AG87Ez"},"source":["For UNIX-based OS users, the following cell will download a dictionary (it's just a list of thai words). Alternatively, you can download it from this link: https://raw.githubusercontent.com/PyThaiNLP/pythainlp/dev/pythainlp/corpus/words_th.txt"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":63,"status":"ok","timestamp":1675821102082,"user":{"displayName":"Paisit Khanarsa","userId":"13279666281938719332"},"user_tz":-420},"id":"EFVR9LO187Ez","outputId":"1f38b1ec-8f67-4afe-d173-921993033fbf","scrolled":true},"outputs":[],"source":["#!wget https://raw.githubusercontent.com/PyThaiNLP/pythainlp/dev/pythainlp/corpus/words_th.txt"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":35,"status":"ok","timestamp":1675821102084,"user":{"displayName":"Paisit Khanarsa","userId":"13279666281938719332"},"user_tz":-420},"id":"nqIQzVgE87E0","outputId":"f38bc3d8-83b8-4485-8bc3-af1504b8fdbf"},"outputs":[{"name":"stdout","output_type":"stream","text":["Vocab size: 62069\n"]}],"source":["with open(\"words_th.txt\",encoding='utf-8-sig') as f:\n","    thai_vocab = f.read().splitlines() \n","print(\"Vocab size:\", len(thai_vocab))\n","thai_vocab.extend([\"ๆ\",\"!\"])"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1675821631374,"user":{"displayName":"Paisit Khanarsa","userId":"13279666281938719332"},"user_tz":-420},"id":"LwtodW_5wDkN","outputId":"1a238d7f-e313-483d-ea2e-93e1b82ed657"},"outputs":[{"data":{"text/plain":["True"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["\"ไป\" in thai_vocab"]},{"cell_type":"markdown","metadata":{"id":"Kpjwzw1w87E0"},"source":["### The output of your maximal matching algoithm on a new dictionary\n","Expected output:\n","<br>\n","[1, 1, 100000, 1, 100000, 100000, 100000, 100000, 100000] ไ\n","<br>\n","[None, 2, 100000, 100000, 100000, 100000, 100000, 100000, 100000] ป\n","<br>\n","[None, None, 2, 2, 2, 100000, 100000, 100000, 100000] ห\n","<br>\n","[None, None, None, 100000, 100000, 100000, 100000, 100000, 100000] า\n","<br>\n","[None, None, None, None, 2, 100000, 100000, 100000, 2] ม\n","<br>\n","[None, None, None, None, None, 100000, 3, 100000, 100000] เ\n","<br>\n","[None, None, None, None, None, None, 100001, 100000, 100000] ห\n","<br>\n","[None, None, None, None, None, None, None, 4, 4] ส\n","<br>\n","[None, None, None, None, None, None, None, None, None] ี"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"lYD5ChIS87E0"},"outputs":[{"name":"stdout","output_type":"stream","text":["[inf, 1, inf, 1, inf, inf, inf, inf, inf] ไ\n","[None, inf, inf, inf, inf, inf, inf, inf, inf] ป\n","[None, None, inf, 2, 2, inf, inf, inf, inf] ห\n","[None, None, None, inf, inf, inf, inf, inf, inf] า\n","[None, None, None, None, inf, inf, inf, inf, 2] ม\n","[None, None, None, None, None, inf, 3, inf, inf] เ\n","[None, None, None, None, None, None, inf, inf, inf] ห\n","[None, None, None, None, None, None, None, inf, 4] ส\n","[None, None, None, None, None, None, None, None, inf] ี\n"]}],"source":["input_text = \"ไปหามเหสี\"\n","out = maximal_matching(input_text)\n","for i in range(len(out)):\n","    print(out[i],input_text[i])"]},{"cell_type":"markdown","metadata":{"id":"BSqLuK7G87E0"},"source":["### Expected tokenized text\n","ไปหา|มเหสี"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"TI077jmy87E0"},"outputs":[{"name":"stdout","output_type":"stream","text":["ไปหา|มเหสี\n"]}],"source":["print_tokenized_text(out,input_text)"]},{"cell_type":"markdown","metadata":{"id":"VLGgO8PrLSz6"},"source":["## Part3) Maximal Matching from PythaiNLP"]},{"cell_type":"markdown","metadata":{"id":"LrZrzQoXLeUX"},"source":["### Default dictionary\n","\n","Study word_tokenize() from PythaiNLP in the link below.\n","\n","https://thainlp.org/pythainlp/docs/2.0/api/tokenize.html"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"yXxPBOcNLXfm"},"outputs":[],"source":["# !pip install pythainlp\n","# !pip install marisa_trie"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"goQE5gFUL4KO"},"outputs":[{"data":{"text/plain":["['นัด', 'กินกัน', 'ตอน', 'ไหน', 'ก็', 'ได้ที่', 'สามย่าน', 'มิตร', 'ทาวน์']"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["from pythainlp.tokenize import word_tokenize\n","text='นัดกินกันตอนไหนก็ได้ที่สามย่านมิตรทาวน์'\n","\n","####FILL CODE HERE####\n","\n","word_tokenize(text, engine='newmm', keep_whitespace=False)\n","\n","######################"]},{"cell_type":"markdown","metadata":{"id":"2SlX5cEBMHPd"},"source":["### Custom dictionary\n","\n","Add 'สามย่านมิตรทาวน์' into dictionary and then tokenize again"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"b4V9TqFaMPAj"},"outputs":[{"data":{"text/plain":["['นัด', 'กินกัน', 'ตอน', 'ไหน', 'ก็', 'ได้ที่', 'สามย่านมิตรทาวน์']"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["####FILL CODE HERE####\n","from marisa_trie import Trie\n","\n","thai_vocab.extend([\"สามย่านมิตรทาวน์\"])    #add word in dict list\n","trie = Trie(thai_vocab)                 #create trie\n","\n","word_tokenize(text, custom_dict=trie, engine='newmm', keep_whitespace=False)\n","######################"]}],"metadata":{"colab":{"collapsed_sections":["DF5Pme7CK3YF","xzs0R06q87Et","ZornooGF87Ew","w7vBXfjM87Ew","q0MJkKsh87Ex","57rP9cTU87Ez","Kpjwzw1w87E0","BSqLuK7G87E0","VLGgO8PrLSz6","LrZrzQoXLeUX","2SlX5cEBMHPd"],"provenance":[]},"kernelspec":{"display_name":"nlp","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"},"vscode":{"interpreter":{"hash":"97c267b1f2113ed722464dc9bd49a318e7d979aff4433b0f75162aa4b606adbd"}}},"nbformat":4,"nbformat_minor":0}
